---
title: "Casual Inference Final Project"
author: "Linke Bai, Max Zhang, Vincent Wang"
date: "12/2/2021"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{css style settings, echo = FALSE}
.text-box {
    padding: 10px 20px;
    margin: 0 0 20px;
    font-size: 14px;
    border-left: 5px solid #eee;
    border-right: 5px solid #eee;
    border-top: 5px solid #eee;
    border-bottom: 5px solid #eee;
}
```
# Do Expert Reviews Affect the Demand for Wine?

## Introduction

### Description of the paper

The paper that our group selected for this assignment examines how expert reviews influence the demand for wine in Sweden. The researchers used Dynamic Panel Regression to estimate the relationship between expert review and wine sales by introducing lead and lag terms to linear regression model. To confirm whether the effect of reviews varies across different types of wine, the researchers also included a series of interaction terms in the original model to allow review indicators to interact with categories of interest.

### Data 

Weekly sales data on wine is Sweden from Jan 2002 to the first two weeks of 2007 is analyzed by author. The data covers all red , white, and sparkling win sold in 750 ml bottles or in 3 liter packages, which account for more than 96% of the retail market. A wine is defined according to the producer, grape type, container size, coupled with special indications on the label. 10 segments were defined to accommodate the fixed effect of different combination of wine, vintage and price. There are 4 segments of red wine, 4 segments of white wine, and 2 segments of sparkling wine. 

All wines in Sweden is distributed at different levels, while the author only focused on wines that are distributed in more than 375 stores, which account for 77.4% of the market volume. The advertising expenditure per wine per week is also analyzed. 

The review data is collected from 6 major print media sources, which are considered the most influential wine reviews in Sweden. All reviews provides a numerical grade that sets quality in relation to price, which is converted to a 0-10 scale in the data. There are situations when a wine receives conflicting reviews from different sources, the grades from all reviews are positively correlated with each other. 

### Description of the Graph to be Replicated

Our group decided to replicate the summary graph of the first baseline model in the empirical models. The graph consists of 6 individual plots that shows the estimated coefficients from 3 separate models on the sales of wine: model with all review data, model with AOM review data, and model with non-AOM review data. The first 4 four plots are based on the model with all review data and separately focus on the effect of review, good review, bad review, and advertisement expenditure. The 5th plot focus on the effect of good review in the model with AOM review only, while the last plot shows the effect of good review in the model with non-AOM review only. 

The target graph summarizes the key results of the baseline model, and help set up an initial understanding on the relationship between expert reviews and wine sales. The further analysis and models that investigate the interaction terms in the later contents are all based on and derived from this. 

#### Empirical Approach 
$$
lnQ_{ijkt} = \alpha_j + \delta_{kt}+ \sum_{l=-4}^{25}\alpha_{t-l}^{good}R_{it-l}^{good}+\sum_{l=-4}^{25}\alpha_{t-l}R_{it-l}+\sum_{l=-4}^{25}\alpha_{t-l}^{bad}R_{it-l}^{bad}+\sum_{l=-4}^{25}\gamma_{t-l}ADVERT_{it-l}+\eta_{ijkt}
$$

- i:  Wine Product Number
- j: Price*week combination
- k: Product Segment
- t: Week
- R: dummy, if the wine has received any reviews
- $R^{good}$: dummy,if the wine has received review grades greater than 8
- $R^{bad}$: dummy,if the wine has received review grades less than 4

- The dependent variable: Natural log of liters sold of wine i, with vintage and price combination j, sold in segment k during week t

- Two fixed effects are involved: 
1.$\alpha_j:$Fixed Effect of Product Number * Price * Vintage. 
2.$\delta_{kt}$: Fixed effect of time trends in sales (period-color-price segment-package).

### Experiment Motivation




## Replication
#### Read and Clean Data
```{r, message=FALSE, warning=FALSE}
library(ggplot2)
library(fixest)
library(tidyverse)
library(broom)

data <- read.csv("wine_data.csv")
data$date <- as.Date(data$date,format='%d %b %y')
#Change variable names to the same notation as the equation
data <- data %>%
  rename(brand = artikelid, #ID number of Brand
         i = artikelnr,  #ID number of wine
         advert = ma_split,  #AD expenditure
         j = artikpr, #product number-price-vintage combination
         tk = time_segm_price, #period-color-price segment-package indicator
         Q = llitre, #weekly sale in log litre
         R = rev_all, #indicator of wine being reviewed
         R_good = rev_all_hi, #Indicator of the wine receiving a good review (all
         R_bad = rev_all_lo, #Indicator of the wine receiving a bad review (all
         R_aom = rev_ex_hi, #Indicator of the wine receiving a good review in AoM 
         R_aom2 = rev_ex_lo, #Indicator of the wine receiving a bad review in AoM 
         R_naom = rev_nyaom_hi, #Indicator of good reviews not in AoM yearly special
         R_naom2 = rev_nyaom_lo #Indicator of bad reviews not in AoM yearly special 
         )

#change to factor
data$j = as.factor(data$j)
data$tk = as.factor(data$tk)

data$advert[is.na(data$advert)] = 0

#Filter data based on distribution level
dataset <- data %>%
  filter(dist %in% c('5','6'))
```

#### Build Estimation Models

```{r, warning= FALSE}
# Models with All Reviews
fit_base <- feols(Q ~ l(R, -4:25)+l(R_good, -4:25) +l(R_bad, -4:25)+l(advert, -4:25) | j + tk, panel.id = ~ i + period, cluster = ~ brand, data = dataset)

# Models with Reviews on AOM only
fit_aom <- feols(Q ~ l(R_aom, -4:25)+l(R_aom2, -4:25) +l(advert, -4:25) | j + tk, panel.id = ~ i + period, cluster = ~ brand, data = dataset)

#Models with reviews not on AOM only
fit_naom <- feols(Q ~ l(R_naom, -4:25)+l(R_naom2, -4:25) +l(advert, -4:25) | j + tk, panel.id = ~ i + period, cluster = ~ brand, data = dataset)

```

#### Visualize the Coefficients

```{r}
par(mfrow = c(3,2))
#Reviews in all review model
coefplot(fit_base, keep =  'R[^_]|^R$', 
         main = "Reviews",
         xlab = "week",
         ylab = "log liter")
#Good reviews in all review model
coefplot(fit_base, keep =  'R_good[^_]|^R_good$',
         main = "Good Review",
         xlab = "week",
         ylab = "log liter")
#Bad reviews in all review model
coefplot(fit_base, keep = 'R_bad[^_]|^R_bad$',
         main = "Bad Review",
         xlab = "week",
         ylab = "log liter")
#Advertisement in all review model
coefplot(fit_base, keep = 'advert[^_]|^advert$',
         main = "Advertising expenditures",
         xlab = "week",
         ylab = "log liter")
#Good review in AOM Review only model
coefplot(fit_aom, keep = 'R_aom[^2]|^R_aom$',
         main = "Good Review: AOM Yearly Test",
         xlab = "week",
         ylab = "log liter")
#Good review in non-AOM review model
coefplot(fit_naom, keep = 'R_naom[^2]|R_naom$',
         main = "Good Review: Non-Aom yearly test",
         xlab = "week",
         ylab = "log liter")
```

### Replication Differences

There are some small differences in the coefficients we got comparing to the paper as the raw data provided by the author is not identical to what he described in the paper. Specifically, the data provided by the author is missing the 1st month of data in 2017 which was mentioned in the paper. The author also mentioned there are 64,863 observations after initial cleaning stage while we have 76,379 observations after going through the same procedure. There are also some differences in the summary statistics regarding the number of red wines and sparking wines in the data. 

Nevertheless, the replication result we created are very close to what the author achieved in the original paper. Despite the small numeric difference in some of the coefficients, it shows the same patterns and behaviors as in the paper. Overall, our results suggests a slightly greater effect of expert wine reviews on the log sales of wine. 

### Experiment Motivation 

#### Description

Our group believed that there might be other confounders that the authors failed to take into consideration and wondered how those factors would affect the causal estimation.

Based on our personal experience and understanding of the wine industry, we reckoned that if a particular type of wine is being served in a fine-dining restaurant, the sales-boosting impact of positive reviews would be magnified. Such hypothesis motivated us to simulate new data and see whether the proposed *fine-dining effect* would substantially influence the model estimation.


#### Causal Model

$$
Q \sim \delta_i + \delta_t+ \sum_{l=-2}^{4}\delta_{t-l}R_{i,t-l}
$$
Q: log sales of the wine 
j:
t:
R:

#### Data Simulation

```{r}
r = c(0.005672567,0.006215906,0.014258187,0.022125058,0.016683916,0.011528443,0.009721088)
rest = c(0.0015, 0.0015, 0.0015, 0.002, 0.002, 0.002, 0.002)

simulate_data <- function(
  N_units = 10,
  T0 = 1, T1 = 100,
  delta = r,
  rrest = rest,
  pi=0.03,gamma=0.05,sigma_U=0.01,sigma_Y=0.02
){
  N_periods <- T1 - T0 + 1
  N_obs <- N_units*N_periods
  
  tibble(
    i = rep(1:N_units,times=1,each=N_periods),
    t = rep(T0:T1,times=N_units,each=1),
  ) %>% 
    
    #unit FE
  group_by(i) %>%
  mutate(    
    U_i = runif(1,0,1)
  ) %>%
      
   #time period FE
  group_by(t) %>%
  mutate(    
    U_t = gamma*t + rnorm(1,0,sigma_U)
  ) %>%
    
  ungroup() %>%
  
  mutate(
    R = rbinom(N_obs,1,pi),
    Y0 = U_i + U_t + rnorm(N_obs,0,sigma_Y)
  ) %>%
    
  group_by(i) %>%
  mutate(
    Y = Y0 + delta[1]*dplyr::lag(R,2) + delta[2]*dplyr::lag(R) + delta[3]*R + delta[4]*dplyr::lead(R) + delta[5]*dplyr::lead(R,2) + delta[6]*dplyr::lead(R,3) + delta[7]*dplyr::lead(R,4) + rrest[1]*dplyr::lag(R,2) + rrest[2]*dplyr::lag(R,1) + rrest[3]*dplyr::lag(R) + rrest[4]*dplyr::lead(R,2) + rrest[5]*dplyr::lead(R,2) + rrest[6]*dplyr::lead(R,3) + rrest[7]*dplyr::lead(R,4)
  ) %>%
    
  ungroup()
}

head(
  simulate_data()
)
```

```{r}
sim_data <- simulate_data()
arrange(sim_data,i)
```


## Simulation using `fixest::feols`

```{r}
estimator <- function(
  reg_data = sim_data
){
 sim_model <- feols(Y ~ l(R, -2:4) | i + t, panel.id = ~ i + t, 
                    cluster = ~ i, data = reg_data)
 
 point_estimate <- sim_model$coefficients
 
 ci <- confint(sim_model)
 
 estimate <- c(point_estimate[1],ci[1,1],ci[1,2],point_estimate[2],ci[2,1],ci[2,2],point_estimate[3],ci[3,1],ci[3,2],point_estimate[4],ci[4,1],ci[4,2],point_estimate[5],ci[5,1],ci[5,2],point_estimate[6],ci[6,1],ci[6,2],point_estimate[7],ci[7,1],ci[7,2])
 
 names(estimate) <- c('r_hat1','ci_lower1','ci_upper1','r_hat2','ci_lower2','ci_upper2','r_hat3','ci_lower3','ci_upper3','r_hat4','ci_lower4','ci_upper4','r_hat5','ci_lower5','ci_upper5','r_hat6','ci_lower6','ci_upper6','r_hat7','ci_lower7','ci_upper7')
 
 estimate
}

estimator()
```

```{r}
#Creating confidence intervals for each of the previous regressions

par(mfrow = c(2,1))
fit_base %>%
  coefplot(keep = 'R[^_]|^R$', xlim = c(3,9))
feols(Y ~ l(R, -2:4) | i + t, panel.id = ~ i + t, cluster = ~ i, data = sim_data) %>%
  coefplot(keep = 'R[^_]|^R$')

```



```{r warning=FALSE, message=FALSE}
mc_estimate <- function(s){
  sim_data <- simulate_data()
  
  estimate <- estimator(reg_data = sim_data)
  
  estimate
}

feols_estimates <- 1:100 %>%
  map_df(mc_estimate, .id = 'Sample')

head(feols_estimates,10)
```

```{r}
feols_estimates <- feols_estimates %>%
    mutate(error1 = r_hat1 - r[1]) %>%
    mutate(error2_1 = error1^2) %>%
    mutate(in_ci1 = as.integer((ci_lower1 <= (r[1])) & ((r[1]) <= ci_upper1))) %>%
    mutate(error2 = r_hat2 - r[2]) %>%
    mutate(error2_2 = error2^2) %>%
    mutate(in_ci2 = as.integer((ci_lower2 <= (r[2])) & ((r[2]) <= ci_upper2))) %>%
    mutate(error3 = r_hat3 - r[3]) %>%
    mutate(error2_3 = error3^2) %>%
    mutate(in_ci3 = as.integer((ci_lower3 <= (r[3])) & ((r[3]) <= ci_upper3))) %>%
    mutate(error4 = r_hat4 - r[4]) %>%
    mutate(error2_4 = error4^2) %>%
    mutate(in_ci4 = as.integer((ci_lower4 <= (r[4])) & ((r[4]) <= ci_upper4))) %>%
    mutate(error5 = r_hat5 - r[5]) %>%
    mutate(error2_5 = error5^2) %>%
    mutate(in_ci5 = as.integer((ci_lower5 <= (r[5])) & ((r[5]) <= ci_upper5))) %>%
    mutate(error6 = r_hat6 - r[6]) %>%
    mutate(error2_6 = error6^2) %>%
    mutate(in_ci6 = as.integer((ci_lower6 <= (r[6])) & ((r[6]) <= ci_upper6))) %>%
    mutate(error7 = r_hat7 - r[7]) %>%
    mutate(error2_7 = error7^2) %>%
    mutate(in_ci7 = as.integer((ci_lower7 <= (r[7])) & ((r[7]) <= ci_upper7)))
```


```{r}

#Generating t test for each of the errors for each lead and lag
t_bias_lead2 <- t.test(feols_estimates$error1)
t_bias_lead1 <- t.test(feols_estimates$error2)
t_bias_r <- t.test(feols_estimates$error3)
t_bias_lag1<- t.test(feols_estimates$error4)
t_bias_lag2 <- t.test(feols_estimates$error5)
t_bias_lag3 <- t.test(feols_estimates$error6)
t_bias_lag4 <- t.test(feols_estimates$error7)

#Generating the coverage of each lead and lag 
t_coverage_lead2 <- t.test(feols_estimates$in_ci1,mu=0.95)
t_coverage_lead1 <- t.test(feols_estimates$in_ci2,mu=0.95)
t_coverage_r <- t.test(feols_estimates$in_ci3,mu=0.95)
t_coverage_lag1 <- t.test(feols_estimates$in_ci4,mu=0.95)
t_coverage_lag2 <- t.test(feols_estimates$in_ci5,mu=0.95)
t_coverage_lag3 <- t.test(feols_estimates$in_ci6,mu=0.95)
t_coverage_lag4 <- t.test(feols_estimates$in_ci7,mu=0.95)

#Generating summary bias tables for each lead and lag
test_results_lead2 <- map_df(list(t_bias_lead2,t_coverage_lead2),tidy) %>%
  mutate(statistic = c('Bias','Coverage')) %>%
  mutate(H_0 = c(0,0.95)) %>%
  mutate(Instance = 'Lead2')

test_results_lead1 <- map_df(list(t_bias_lead1,t_coverage_lead1),tidy) %>%
  mutate(statistic = c('Bias','Coverage')) %>%
  mutate(H_0 = c(0,0.95)) %>%
  mutate(Instance = 'Lead1')

test_results_r <- map_df(list(t_bias_r,t_coverage_r),tidy) %>%
  mutate(statistic = c('Bias','Coverage')) %>%
  mutate(H_0 = c(0,0.95)) %>%
  mutate(Instance = 'Treatment')
test_results_lag1 <- map_df(list(t_bias_lag1,t_coverage_lag1),tidy) %>%
  mutate(statistic = c('Bias','Coverage')) %>%
  mutate(H_0 = c(0,0.95)) %>%
  mutate(Instance = 'Lag1')
test_results_lag2 <- map_df(list(t_bias_lag2,t_coverage_lag2),tidy) %>%
  mutate(statistic = c('Bias','Coverage')) %>%
  mutate(H_0 = c(0,0.95)) %>%
  mutate(Instance = 'Lag2')
test_results_lag3 <- map_df(list(t_bias_lag3,t_coverage_lag3),tidy) %>%
  mutate(statistic = c('Bias','Coverage')) %>%
  mutate(H_0 = c(0,0.95)) %>%
  mutate(Instance = 'Lag3')

test_results_lag4 <- map_df(list(t_bias_lag4,t_coverage_lag4),tidy) %>%
  mutate(statistic = c('Bias','Coverage')) %>%
  mutate(H_0 = c(0,0.95)) %>%
  mutate(Instance = 'Lag4')

#Creating one bias summary data table for all leads and lags 
test_results <- data.frame(rbind(test_results_lead2,test_results_lead1, test_results_r, test_results_lag1, test_results_lag2, test_results_lag3, test_results_lag4))
knitr::kable(test_results[c('Instance','statistic','estimate','H_0','p.value','conf.low','conf.high')])


t_coverage_lag1
```



